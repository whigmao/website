---
title: Bayesian Inference and Decision Theory 2
author: Guanghua Mao
date: '2020-03-02'
slug: bayesian-inference-and-decision-theory-2
categories:
  - Decision Theory
tags:
  - Bayesian
  - R
  - Data Science
---

# Unit 2: Random Variables, Parametric Models, and Inference from Observation

# Random Variable and Distribution Functions

A random variable is a function from the sample space Ω to a set of outcomes.

* **Cumulative distribution function (cdf)** - Value of cdf at $x$ is probability that the random variable is less than or equal to $x$.

* **Probability mass function (pmf)** - Maps each possible value of a discrete random variable to its probability

* **Probability density function (pdf)** - Maps each possible value of a continuous random variable to a positive number representing its likelihood relative to other possible values

# Central Tendency and Spread

Mean, Median and Mode.

Variance, Standard Deviation, Median absolute deviation adn Credible interval.

# Multivariate Random Variables

A joint distribution (also called a multivariate distribution) defines a probability distribution on several random variables.

**Pay attention to marginal distribution and conditional distribution.**

* The **covariance** matrix measures how random quantities vary together.

  * If $X_i$ and $X_j$ are independent then $Cov(X_i,X_j) = 0$.
  
* The **correlation matrix**

  * The off-diagonal elements are real numbers between -1 and 1
  * If RVs are independent then correlation is zero
  * The closer the correlation is to 1 or -1, the more nearly linearly related the RVs are
  
  
# Independence and Conditional Independence

$\underline{\mathbf{X}}$ and $\underline{\mathbf{Y}}$ are **independent** if the conditional distribution of $\underline{\mathbf{X}}$ given $\underline{\mathbf{Y}}$ does not depend on $\underline{\mathbf{Y}}$.

$f(\underline{\mathbf{x}},\underline{\mathbf{y}})=f(\underline{\mathbf{x}}) \cdot f(\underline{\mathbf{y}})$.


$\underline{\mathbf{X}}$ and $\underline{\mathbf{Y}}$ are **conditionally independent** given $\underline{\mathbf{Z}}$ if:

$f(\underline{\mathbf{x}}, \underline{\mathbf{y}}, \underline{\mathbf{z}})=f(\underline{\mathbf{x}}|\underline{\mathbf{z}}) \cdot f(\underline{\mathbf{y}}|\underline{\mathbf{z}}) \cdot f(\underline{\mathbf{z}})$

Conditional independence relationships simplify specificiation of the joint distribution.

---

# Parametric Families of Distributions


Statistics makes use of parametric families of distributions. Many problems are modeled by assuming observations $X_1, …, X_N$ are independent and identically distributed observations from a distribution with gpdf $f(x|unknowm \ paremeter)$.

There are four steps for the canonical problems:

1. Use sample to construct an estimate (point or interval) of $unknowm \ paremeter$

2. Test a hypothesis about the value of $unknowm \ paremeter$

3. Is the functional form $f(x|unknowm \ paremeter)$ an adequate model for the data?

4. Predict features (e.g., mean) of a future sample


Many distributions have multiple parameterizations in common use and it is important not to confuse different parameterizations.


# Distribution in R

In R, there are four functions for each distribution, invoked by adding a prefix to the distribution’s base name:

* p for **probability** – the cumulative distribution function (cdf)

* p for **probability** – the cumulative distribution function (cdf)

* d for **density** – the density or mass function

* r for **random** – generates random numbers from the distribution

Statistical models often assume the observations are a random sample from a parameterized distribution.


# Is a Parametric Distribution a Good Model?

Before applying a parametric model, we should assess its adequacy:

* Theoretical assumptions underlying the distribution

* Exploratory data analysis

* Formal goodness-of-fit tests

A q-q plot is a commonly used diagnostic tool. The plot shows quantiles of data distribution against quantiles of theoretical distribution. If theoretical distribution is correct, the plot should look approximately like the plot of $y=x$. The problem is what if the paremeters are unknown. The parameters can be estimated from data. 

Another diagnostic tool is to compare empirical and theoretical counts for discrete RV.

# Example: Modeling Transmission Errors

Number of transmission errors per hour is distributed as Poisson with parameter $\lambda$.

$f(x|\lambda)=\frac{e^{-\lambda} \cdot \lambda^x}{x!}$.

Data on previous system established error rate as 1.6 errors per hour. New system has design goal of cutting this rate in € half to 0.8 errors per hour. 

Observe new system for 6 one-hour periods: 

  * Data: 1,0,1,2,1,0
  
Have we met the design goal? Does the new system improve the error rate?

We use expert judgment to define prior distribution on a discrete set of values. Experts familiar with the new system design said: "Meeting the design goal of 0.8 errors per hour is about a 50-50 proposition. The chance of making things worse than current rate of 1.6 errors per hour is small but not negligible." Expert agrees that the discretized distribution shown here is a good reflection of his prior knowledge:

* Expected value is about 1.0

* Distribution is heavy tailed on the right

* $P(Λ≤0.8) = 0.54$

* $P(Λ≤1.6) = 0.87$

* Values of $Λ$ greater than 3 are unlikely enough to ignore

## Features of the Posterior Distribution

Central tendency:

* Posterior mean of $Λ$ is 0.87

* Prior mean of $Λ$ is 0.97; data mean is .83

* Typically posterior central tendency is a compromise between the prior distribution and the center of the data

Variation:

* Posterior standard deviation of $Λ$ is about 0.33

* Prior standard deviation of $Λ$ is about 0.62

* Typically variation in the posterior is less than variation in the prior (we have more information)

Meeting the threshold

* Posterior probability of meeting or doing better than design goal is about 0.58

* Posterior probability that new system is better than old system is about 0.96

* Posterior probability that new system is worse than old system is less than 0.02

## Triplot

Triplot is a visual tool for examining Bayesian belief dynamics. It plots prior distribution, normalized likelihood, and posterior distribution.

## Bayesian Belief Dynamics:

Batch processing:

* Use Bayes rule with prior  and combined likelihood $f(X_1, …, X_n |\theta)$ to find posterior $f(\theta|X_1, …, X_n )$

Sequential processing:

* Use Bayes rule with prior $g(\theta)$ and likelihood $f(X_1|\theta)$ to find posterior $f(\theta|X_1)$

* Use Bayes rule with prior $g(\theta|X_1)$ and likelihood $f(X_2|\theta)$ to find posterior $f(\theta|X_1,X_2)$

…

* Use Bayes rule with prior $g(\theta|X_1, …, X_{n-1})$ and likelihood $f(X_n|\theta)$ to find posterior $f(\theta|X_1,X_2,…,X_n)$

* The posterior distribution after n observations is the same with both methods


# Fundamental Identity of Bayesian Inference

![Byesian Inference](/post/2020-03-02-bayesian-inference-and-decision-theory-2_files/rrr.png)

## Marginal Likelihood

Before we have seen $X$, we use the marginal likelihood to predict the value of $X$.

* When used for predicting $X$, the marginal likelihood is called the predictive distribution for $X$.

After we see $X=x$, we divide the joint probability $f(x|\theta)g(\theta)$ by the marginal

likelihood $f(x)$ to obtain the posterior probability of $\theta$:

$g(\theta|x)=\frac{f(x|\theta)g(\theta)}{f(x)}$

* The marginal likelihood $f(x)$ is the normalizing constant in Bayes Rule – we divide by $f(x)$ to ensure that the posterior probabilities sum to 1.

# Bayesian Inference for Continuous Random Variables

Inference for continuous random variable is limiting case of inference with discretized random variable as number of bins and width of bin goes to zero.

* Accuracy tends to increase with more bins

* Accuracy tends to increase with smaller area per bin

* Be careful with tail area of unbounded random variables

* Closed form solution for continuous problem exists in special cases (see Unit 3)






  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
