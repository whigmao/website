---
title: 'Introduction to statistical learning 02---Statistical Learning'
author: Guanghua Mao
date: '2021-09-13'
slug: '307'
categories:
  - Translation Articles
tags:
  - Book
  - Book Review
  - Statistical
  - Programming
  - Prediction
  - Nonlinear system
  - Data Science
output:
  blogdown::html_page:
    toc: true
    number_sections: true
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#what-is-statistical-learning"><span class="toc-section-number">1</span> What is Statistical Learning?</a>
<ul>
<li><a href="#why-estimate-f"><span class="toc-section-number">1.1</span> Why Estimate <span class="math inline">\(f\)</span>?</a>
<ul>
<li><a href="#prediction"><span class="toc-section-number">1.1.1</span> Prediction</a></li>
<li><a href="#inference"><span class="toc-section-number">1.1.2</span> Inference</a></li>
</ul></li>
<li><a href="#how-do-we-estimate-f"><span class="toc-section-number">1.2</span> How Do We Estimate <span class="math inline">\(f\)</span>?</a>
<ul>
<li><a href="#parametric-methods"><span class="toc-section-number">1.2.1</span> Parametric Methods</a></li>
<li><a href="#non-parametric-methods"><span class="toc-section-number">1.2.2</span> Non-Parametric Methods</a></li>
</ul></li>
<li><a href="#the-trade-off-between-prediction-accuracy-and-model"><span class="toc-section-number">1.3</span> The Trade-Off Between Prediction Accuracy and Model</a></li>
<li><a href="#supervised-versus-unsupervised-learning"><span class="toc-section-number">1.4</span> Supervised Versus Unsupervised Learning</a></li>
<li><a href="#regression-versus-classification-problems"><span class="toc-section-number">1.5</span> Regression Versus Classification Problems</a></li>
</ul></li>
<li><a href="#assessing-model-accuracy"><span class="toc-section-number">2</span> Assessing Model Accuracy</a>
<ul>
<li><a href="#measuring-the-quality-of-fit"><span class="toc-section-number">2.1</span> Measuring the Quality of Fit</a></li>
<li><a href="#the-bias-variance-trade-off"><span class="toc-section-number">2.2</span> The Bias-Variance Trade-Off</a></li>
<li><a href="#the-classification-setting"><span class="toc-section-number">2.3</span> The Classification Setting</a>
<ul>
<li><a href="#the-bayes-classifier"><span class="toc-section-number">2.3.1</span> The Bayes Classifier</a></li>
<li><a href="#k-nearest-neighbors"><span class="toc-section-number">2.3.2</span> K-Nearest Neighbors</a></li>
</ul></li>
</ul></li>
</ul>
</div>

<div id="what-is-statistical-learning" class="section level1" number="1">
<h1><span class="header-section-number">1</span> What is Statistical Learning?</h1>
<p>The input variables are typically denoted using the symbol <span class="math inline">\(X\)</span>, with a subscript to distinguish them. The inputs go by different names, such as predictors, independent variables, features, or sometimes just variables. The output variable is often called the response or dependent variable, and is typically denoted using the symbol <span class="math inline">\(Y\)</span>.</p>
<p>More generally, suppose that we observe a quantitative response <span class="math inline">\(Y\)</span> and <span class="math inline">\(p\)</span>
different predictors, <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, . . . , <span class="math inline">\(X_p\)</span>. We assume that there is some
relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X = (X_1, X_2, . . . , X_p)\)</span>, which can be written
in the very general form</p>
<center>
<span class="math inline">\(Y=f(X)+\epsilon\)</span>
</center>
<p>Here <span class="math inline">\(f\)</span> is some fixed but unknown function of <span class="math inline">\(X_1, . . . , X_p\)</span>, and <span class="math inline">\(\epsilon\)</span> is a random
error term, which is independent of <span class="math inline">\(X\)</span> and has mean zero. In this formulation f represents the systematic information that <span class="math inline">\(X\)</span> provides about <span class="math inline">\(Y\)</span>.</p>
<p>In essence, statistical learning refers to a set of approaches for estimating
<span class="math inline">\(f\)</span>. In this chapter we outline some of the key theoretical concepts that arise
in estimating <span class="math inline">\(f\)</span>, as well as tools for evaluating the estimates obtained.</p>
<div id="why-estimate-f" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Why Estimate <span class="math inline">\(f\)</span>?</h2>
<p>There are two main reasons that we may wish to estimate <span class="math inline">\(f\)</span>: prediction
and inference.</p>
<div id="prediction" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Prediction</h3>
<p>In many situations, a set of inputs <span class="math inline">\(X\)</span> are readily available, but the output
<span class="math inline">\(Y\)</span> cannot be easily obtained.</p>
<p>The accuracy of <span class="math inline">\(\hat{Y}\)</span> as a prediction for <span class="math inline">\(Y\)</span> depends on two quantities,
which we will call the reducible error and the irreducible error.</p>
<p>This is known
as the irreducible error, because no matter how well we estimate <span class="math inline">\(f\)</span>, we
cannot reduce the error introduced by <span class="math inline">\(\epsilon\)</span>. Why is the irreducible error larger than zero? The quantity <span class="math inline">\(\epsilon\)</span> may contain unmeasured variables that are useful in predicting <span class="math inline">\(Y\)</span> : since we don’t
measure them, <span class="math inline">\(f\)</span> cannot use them for its prediction. The quantity <span class="math inline">\(\epsilon\)</span> may
also contain unmeasurable variation.</p>
<p>The focus is on techniques for estimating <span class="math inline">\(f\)</span> with the aim of
minimizing the reducible error. It is important to keep in mind that the
irreducible error will always provide an upper bound on the accuracy of
our prediction for <span class="math inline">\(Y\)</span> . This bound is almost always unknown in practice.</p>
<blockquote>
<p>让人想起了<a href="http://headsalon.org/archives/7329.html">这篇博客</a>以及<a href="https://guanghuamao.netlify.app/2020/09/06/17/#%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%95%99%E8%AF%B2">这篇文章</a></p>
</blockquote>
</div>
<div id="inference" class="section level3" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Inference</h3>
<p>We are often interested in understanding the association between Y and
X1, . . . , Xp. In this situation we wish to estimate f, but our goal is not
necessarily to make predictions for Y . Now <span class="math inline">\(\hat{f}\)</span> cannot be treated as a black
box, because we need to know its exact form. In this setting, one may be
interested in answering the following questions:</p>
<ul>
<li><p>Which predictors are associated with the response?</p></li>
<li><p>What is the relationship between the response and each predictor?</p></li>
<li><p>Can the relationship between <span class="math inline">\(Y\)</span> and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?</p></li>
</ul>
<p>Finally, some modeling could be conducted both for prediction and inference. Depending on whether our ultimate goal is prediction, inference, or a
combination of the two, different methods for estimating <span class="math inline">\(f\)</span> may be appropriate. For example, linear models allow for relatively simple and interpretable inference, but may not yield as accurate predictions as some other
approaches. In contrast, some of the highly non-linear approaches that we
discuss in the later chapters of this book can potentially provide quite accurate predictions for <span class="math inline">\(Y\)</span> , but this comes at the expense of a less interpretable
model for which inference is more challenging.</p>
</div>
</div>
<div id="how-do-we-estimate-f" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> How Do We Estimate <span class="math inline">\(f\)</span>?</h2>
<p>We explore many linear and non-linear approaches
for estimating f. However, these methods generally share certain characteristics. We provide an overview of these shared characteristics in this
section. We will always assume that we have observed a set of <span class="math inline">\(n\)</span> different
data points. These observations are called the training data because we will use these
training
observations to train, or teach, our method how to estimate <span class="math inline">\(f\)</span>. Our goal is to apply a statistical learning method to the training data
in order to estimate the unknown function <span class="math inline">\(f\)</span>. Broadly
speaking, most statistical learning methods for this task can be characterized as either parametric or non-parametric.</p>
<div id="parametric-methods" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Parametric Methods</h3>
<p>Parametric methods involve a two-step model-based approach.</p>
<ol style="list-style-type: decimal">
<li><p>First, we make an assumption about the functional form, or shape,
of <span class="math inline">\(f\)</span>. [预先假设函数的形式恐怕不太好吧，我还是更喜欢 non-linear model]</p></li>
<li><p>After a model has been selected, we need a procedure that uses the
training data to fit or train the model.</p></li>
</ol>
<p>The most common approach to fitting the model is referred to
as (ordinary) least squares. However,
least squares is one of many possible ways to fit the linear model. In
later chapter, we will discuss other approaches for estimating the parameters.</p>
<p>The model-based approach just described is referred to as parametric;
it reduces the problem of estimating <span class="math inline">\(f\)</span> down to one of estimating a set of
parameters. Assuming a parametric form for <span class="math inline">\(f\)</span> simplifies the problem of
estimating <span class="math inline">\(f\)</span> because it is generally much easier to estimate a set of parameters, such as <span class="math inline">\(β_0, β_1, . . . , β_p\)</span> in the linear model, than it is to fit
an entirely arbitrary function <span class="math inline">\(f\)</span>. The potential disadvantage of a parametric approach is that the model we choose will usually not match the true
unknown form of <span class="math inline">\(f\)</span>. If the chosen model is too far from the true <span class="math inline">\(f\)</span>, then
our estimate will be poor. We can try to address this problem by choosing flexible models that can fit many different possible functional forms for <span class="math inline">\(f\)</span>. But in general, fitting a more flexible model requires estimating a
greater number of parameters. These more complex models can lead to a
phenomenon known as overfitting the data, which essentially means they follow the errors, or noise, too closely.</p>
</div>
<div id="non-parametric-methods" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Non-Parametric Methods</h3>
<p>Non-parametric methods do not make explicit assumptions about the functional form of <span class="math inline">\(f\)</span>. Instead they seek an estimate of <span class="math inline">\(f\)</span> that gets as close to the
data points as possible without being too rough or wiggly. Such approaches
can have a major advantage over parametric approaches: by avoiding the
assumption of a particular functional form for <span class="math inline">\(f\)</span>, they have the potential
to accurately fit a wider range of possible shapes for <span class="math inline">\(f\)</span>. Any parametric
approach brings with it the possibility that the functional form used to
estimate <span class="math inline">\(f\)</span> is very different from the true <span class="math inline">\(f\)</span>, in which case the resulting
model will not fit the data well. In contrast, non-parametric approaches
completely avoid this danger, since essentially no assumption about the
form of <span class="math inline">\(f\)</span> is made. But non-parametric approaches do suffer from a major
disadvantage: since they do not reduce the problem of estimating <span class="math inline">\(f\)</span> to a
small number of parameters, a very large number of observations (far more
than is typically needed for a parametric approach) is required in order to
obtain an accurate estimate for <span class="math inline">\(f\)</span>. Overfitting: It is an undesirable situation because
the fit obtained will not yield accurate estimates of the response on new
observations that were not part of the original training data set.</p>
</div>
</div>
<div id="the-trade-off-between-prediction-accuracy-and-model" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> The Trade-Off Between Prediction Accuracy and Model</h2>
<p>Interpretability</p>
<p>Of the many methods that we examine, some are less flexible,
or more restrictive, in the sense that they can produce just a relatively
small range of shapes to estimate <span class="math inline">\(f\)</span>.</p>
<p><img src="1.png" style="width:90.0%" /></p>
<p>One might reasonably ask the following question: why would we ever
choose to use a more restrictive method instead of a very flexible approach?
There are several reasons that we might prefer a more restrictive model.
If we are mainly interested in inference, then restrictive models are much
more interpretable.</p>
<p>In contrast, very flexible
approaches can
lead to such complicated estimates of f that it is difficult to understand
how any individual predictor is associated with the response.</p>
<blockquote>
<p>见 <a href="https://guanghuamao.netlify.app/2020/09/17/22/">The Halo Effect</a>，所以我更加偏爱 flexible approaches.</p>
</blockquote>
<p>We have established that when inference is the goal, there are clear advantages to using simple and relatively inflexible statistical learning methods. In some settings, however, we are only interested in prediction, and
the interpretability of the predictive model is simply not of interest. Surprisingly, this is
not always the case! We will often obtain more accurate predictions using
a less flexible method. This phenomenon, which may seem counterintuitive
at first glance, has to do with the potential for overfitting in highly flexible
methods.</p>
</div>
<div id="supervised-versus-unsupervised-learning" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Supervised Versus Unsupervised Learning</h2>
<p>Most statistical learning problems fall into one of two categories: supervised
supervised
or unsupervised.</p>
<p>For supervised learning, We wish to fit a model that relates the response to the
predictors, with the aim of accurately predicting the response for future
observations (prediction) or better understanding the relationship between
the response and the predictors (inference). By contrast, for unsupervised learning, we can seek to understand the relationships between the variables
or between the observations. However, sometimes the question of whether an analysis
should be considered supervised or unsupervised is less clear-cut. We refer to this setting as
<a href="https://www.goodreads.com/book/show/5403506-introduction-to-semi-supervised-learning?ac=1&amp;from_search=true&amp;qid=Xqz65j0mGr&amp;rank=2">a semi-supervised learning</a> problem.</p>
</div>
<div id="regression-versus-classification-problems" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Regression Versus Classification Problems</h2>
<p>Variables can be characterized as either quantitative or qualitative. Quantitative variables take on numerical values. In contrast, qualitative variables take on values
in one of K different classes, or categories. We tend to refer to problems
with a quantitative response as regression problems, while those involving a qualitative response are often referred to as classification problems.</p>
<p>We tend to select statistical learning methods on the basis of whether
the response is quantitative or qualitative。 However,
whether the predictors are qualitative or quantitative is generally considered less important. Most of the statistical learning methods discussed can be applied regardless of the predictor variable type, provided
that any qualitative predictors are properly coded before the analysis is
performed.</p>
<hr />
</div>
</div>
<div id="assessing-model-accuracy" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Assessing Model Accuracy</h1>
<p>There
is no free lunch in statistics: no one method dominates all others over all
possible data sets. On a particular data set, one specific method may work
best, but some other method may work better on a similar but different
data set. Hence it is an important task to decide for any given set of data
which method produces the best results. Selecting the best approach can
be one of the most challenging parts of performing statistical learning in
practice.</p>
<blockquote>
<p>其实对于人士导师、专业选择、事业方向的建议也同理。详见<a href="https://guanghuamao.netlify.app/2021/07/06/243/">不能乐观过度，无须悲观绝望</a></p>
</blockquote>
<p>In this section, we discuss some of the most important concepts that
arise in selecting a statistical learning procedure for a specific data set.</p>
<div id="measuring-the-quality-of-fit" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Measuring the Quality of Fit</h2>
<p>In order to evaluate the performance of a statistical learning method on
a given data set, we need some way to measure how well its predictions
actually match the observed data. That is, we need to quantify the extent
to which the predicted response value for a given observation is close to
the true response value for that observation. In the regression setting, the
most commonly-used measure is the mean squared error(<span class="math inline">\(MSE\)</span>)</p>
<center>
<span class="math inline">\(MSE=\frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{f}(x))^2\)</span>
</center>
<p>The MSE
will be small if the predicted responses are very close to the true responses, and will be large if for some of the observations, the predicted and true
responses differ substantially.</p>
<p>The MSE discussed is computed using the training data that was used to
fit the model, and so should more accurately be referred to as the training
MSE. But in general, we do not really care how well the method works
training
on the training data. Rather, we are interested in the accuracy of the predictions that we obtain when we apply our method to previously unseen
test data.</p>
<blockquote>
<p>历史经验不一定能够预测未来</p>
</blockquote>
<p>We want to choose the method that gives
the lowest test MSE, as opposed to the lowest training MSE. In other words, if we had a large number of test observations, we could compute</p>
<center>
<span class="math inline">\(AVG(y_0-\hat{f}(x_0))^2\)</span>
</center>
<p>We’d like to select the model for which this quantity is as small as possible.</p>
<p>How can we go about trying to select a method that minimizes the test
MSE? In some settings, we may have a test data set available—that is,
we may have access to a set of observations that were not used to train
the statistical learning method. We can then simply evaluate on the
test observations, and select the learning method for which the test MSE is
smallest. But what if no test observations are available? In that case, one
might imagine simply selecting a statistical learning method that minimizes
the training MSE. This seems like it might be a sensible approach, since the training MSE and the test MSE appear to be closely related. Unfortunately, there is a fundamental problem with this strategy: there
is no guarantee that the method with the lowest training MSE will also
have the lowest test MSE. Roughly speaking, the problem is that many
statistical methods specifically estimate coefficients so as to minimize the
training set MSE. For these methods, the training set MSE can be quite
small, but the test MSE is often much larger.</p>
<div class="figure">
<img src="2.png" alt="" />
<p class="caption">Training MSE (grey curve), test MSE (red
curve), and minimum possible test MSE over all methods (dashed line)</p>
</div>
<p>As the flexibility of the statistical
learning method increases, we observe a monotone decrease in the training
MSE and a U-shape in the test MSE. This is a fundamental property of
statistical learning that holds regardless of the particular data set at hand
and regardless of the statistical method being used. As model flexibility
increases, training MSE will decrease, but the test MSE may not. When
a given method yields a small training MSE but a large test MSE, we are
said to be overfitting the data. This happens because our statistical learning
procedure is working too hard to find patterns in the training data, and
may be picking up some patterns that are just caused by random chance
rather than by true properties of the unknown function <span class="math inline">\(f\)</span>. When we overfit
the training data, the test MSE will be very large because the supposed
patterns that the method found in the training data simply don’t exist
in the test data. Note that regardless of whether or not overfitting has
occurred, we almost always expect the training MSE to be smaller than
the test MSE because most statistical learning methods either directly or
indirectly seek to minimize the training MSE. Overfitting refers specifically
to the case in which a less flexible model would have yielded a smaller
test MSE.</p>
<p>In practice, one can usually compute the training MSE with relative
ease, but estimating test MSE is considerably more difficult because usually
no test data are available. One important method is cross-validation.</p>
<div class="figure">
<img src="3.png" style="width:90.0%" alt="" />
<p class="caption"><span class="math inline">\(f\)</span> is approximately linear</p>
</div>
<div class="figure">
<img src="4.png" style="width:90.0%" alt="" />
<p class="caption"><span class="math inline">\(f\)</span> is highly non-linear</p>
</div>
</div>
<div id="the-bias-variance-trade-off" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> The Bias-Variance Trade-Off</h2>
<p>The U-shape observed in the test MSE curves turns out
to be the result of two competing properties of statistical learning methods. It is
possible to show that the expected test MSE, for a given value <span class="math inline">\(x_0\)</span>, can
always be decomposed into the sum of three fundamental quantities: the
variance of <span class="math inline">\(\hat{f}(x_0)\)</span>, the squared bias of <span class="math inline">\(\hat{f}(x_0)\)</span> and the variance of the error terms <span class="math inline">\(\epsilon\)</span>.</p>
<p>What do we mean by the variance and bias of a statistical learning
method? Variance refers to the amount by which <span class="math inline">\(\hat{f}\)</span> would change if we
estimated it using a different training data set. Since the training data
are used to fit the statistical learning method, different training data sets
will result in a different <span class="math inline">\(\hat{f}\)</span>. But ideally the estimate for <span class="math inline">\(f\)</span> should not vary
too much between training sets. However, if a method has high variance
then small changes in the training data can result in large changes in <span class="math inline">\(\hat{f}\)</span>. In
general, more flexible statistical methods have higher variance.</p>
<p>On the other hand, bias refers to the error that is introduced by approximating a real-life problem, which may be extremely complicated, by a much
simpler model. For example, linear regression assumes that there is a linear
relationship. It is unlikely that any real-life
problem truly has such a simple linear relationship, and so performing linear regression will undoubtedly result in some bias in the estimate of <span class="math inline">\(f\)</span>. Generally, more flexible
methods result in less bias.</p>
<p>As a general rule, as we use more flexible methods, the variance will
increase and the bias will decrease. The relative rate of change of these
two quantities determines whether the test MSE increases or decreases. We increase the flexibility of a class of methods, the bias tends to initially
decrease faster than the variance increases. Consequently, the expected
test MSE declines. However, at some point increasing flexibility has little
impact on the bias but starts to significantly increase the variance. When
this happens the test MSE increases.</p>
<div class="figure">
<img src="5.png" style="width:90.0%" alt="" />
<p class="caption">bias vs variance</p>
</div>
<p>Good test set performance of a statistical learning method requires low variance as well as low squared bias. This is referred to as atrade-off because it is easy to obtain a method with extremely low bias but
high variance (for instance, by drawing a curve that passes through every
single training observation) or a method with very low variance but high
bias (by fitting a horizontal line to the data). The challenge lies in finding
a method for which both the variance and the squared bias are low.</p>
<p>In a real-life situation in which <span class="math inline">\(f\)</span> is unobserved, it is generally not possible to explicitly compute the test MSE, bias, or variance for a statistical
learning method. Nevertheless, one should always keep the bias-variance
trade-off in mind. In this book we explore methods that are extremely
flexible and hence can essentially eliminate bias. However, this does not
guarantee that they will outperform a much simpler method such as linear
regression.</p>
</div>
<div id="the-classification-setting" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> The Classification Setting</h2>
<p>Thus far, our discussion of model accuracy has been focused on the regression setting. But many of the concepts that we have encountered, such
as the bias-variance trade-off, transfer over to the classification setting
with only some modifications due to the fact that <span class="math inline">\(y_i\)</span> is no longer quantitative. Suppose that we seek to estimate <span class="math inline">\(f\)</span> on the basis of training observations <span class="math inline">\({(x_1, y_1), . . . , (x_n, y_n)}\)</span>, where now <span class="math inline">\(y_1, . . . , y_n\)</span> are qualitative. The
most common approach for quantifying the accuracy of our estimate <span class="math inline">\(\hat{f}\)</span> is
the training error rate, the proportion of mistakes that are made if we apply our estimate fˆ to the training observations:</p>
<center>
<span class="math inline">\(\frac{1}{n}\sum_{i=1}^{n}I(y_j\neq\hat{y}_j)\)</span>
</center>
<p>Here <span class="math inline">\(\hat{y}_j\)</span> is the predicted class label for the <span class="math inline">\(i\)</span>th observation using <span class="math inline">\(\hat{f}\)</span>. And
<span class="math inline">\(I(y_j\neq\hat{y}_j)\)</span> is an indicator variable that equals 1 if <span class="math inline">\(y_j\neq\hat{y}_j\)</span> and zero if <span class="math inline">\(y_j=\hat{y}_j\)</span>.
indicator
If <span class="math inline">\(I(y_j\neq\hat{y}_j) = 0\)</span> then the <span class="math inline">\(i\)</span>th observation was classified correctly by our variable
classification method; otherwise it was misclassified.</p>
<p>The equation is referred to as the training error rate because it is computed based on the data that was used to train our classifier. As in the regression setting, we are most interested in the error rates that result from
applying our classifier to test observations that were not used in training. The test error rate associated with a set of test observations of the form <span class="math inline">\((x_0, y_0)\)</span> is given by</p>
<center>
<span class="math inline">\(AVG(I(y_0\neq\hat{y}_0)\)</span>
</center>
<p>A good classifier is one for which
the test error is smallest.</p>
<div id="the-bayes-classifier" class="section level3" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> The Bayes Classifier</h3>
<p>It is possible to show that the test error rate given is minimized, on average, by a
very simple classifier that assigns each observation to the most likely class,
given its predictor values. In other words, we should simply assign a test
observation with predictor vector <span class="math inline">\(x_0\)</span> to the class <span class="math inline">\(j\)</span> for which:</p>
<center>
<span class="math inline">\(Pr(Y=j|X=x_0)\)</span>
</center>
</div>
<div id="k-nearest-neighbors" class="section level3" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> K-Nearest Neighbors</h3>
<p>In theory we would always like to predict qualitative responses using the
Bayes classifier. But for real data, we do not know the conditional distribution of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>, and so computing the Bayes classifier is impossible. Therefore, the Bayes classifier serves as an unattainable gold standard
against which to compare other methods. Many approaches attempt to
estimate the conditional distribution of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>, and then classify a
given observation to the class with highest estimated probability. One such
method is the K-nearest neighbors (KNN) classifier. Given a positive integer <span class="math inline">\(K\)</span> and a test observation <span class="math inline">\(x_0\)</span>, the KNN classifier first identifies the <span class="math inline">\(K\)</span> points in the training data that are closest to <span class="math inline">\(x_0\)</span>, represented by <span class="math inline">\(N_0\)</span>. It then estimates the conditional probability for class <span class="math inline">\(j\)</span> as the fraction of
points in <span class="math inline">\(N_0\)</span> whose response values equal <span class="math inline">\(j\)</span>:</p>
<center>
<span class="math inline">\(Pr(Y=j|X=x_0)=\frac{1}{K}\sum_{i\in N_0}I(y_i = j)\)</span>
</center>
<p>Despite the fact that it is a very simple approach, KNN can often produce classifiers that are surprisingly close to the optimal Bayes classifier.</p>
<p>The choice of K has a drastic effect on the KNN classifier obtained.</p>
<p>When K = 1, the decision boundary is overly
flexible and finds patterns in the data that don’t correspond to the Bayes
decision boundary. This corresponds to a classifier that has low bias but
very high variance. As K grows, the method becomes less flexible and
produces a decision boundary that is close to linear. This corresponds to
a low-variance but high-bias classifier.</p>
<p>Just as in the regression setting, there is not a strong relationship between the training error rate and the test error rate. With K = 1, the
KNN training error rate is 0, but the test error rate may be quite high. In
general, as we use more flexible classification methods, the training error
rate will decline but the test error rate may not. As in the regression setting, the
training error rate consistently declines as the flexibility increases. However,
the test error exhibits a characteristic U-shape, declining at first (with a
minimum at approximately K = 10) before increasing again when the
method becomes excessively flexible and overfits.</p>
<p><img src="6.png" style="width:90.0%" /></p>
<p>In this section, the authors talk about some core concepts for supervised learning: why do we want to estimate <span class="math inline">\(f\)</span>, how to estimate it(parametric and non-parametric), how to measure the accuracy of our estimate, the difference between supervised learning and unsupervised learning, regression and classification, the trade off between flexibility and interpretablity, variance and bias, and soon. Also, the authors explore some methods on classification setting.</p>
</div>
</div>
</div>
