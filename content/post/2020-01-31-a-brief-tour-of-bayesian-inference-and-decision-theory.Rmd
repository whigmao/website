---
title: A Brief Tour of Bayesian Inference and Decision Theory
author: Guanghua Mao
date: '2020-01-31'
slug: a-brief-tour-of-bayesian-inference-and-decision-theory
categories:
  - Decision Theory
tags:
  - Bayesian
  - R
  - Math
---

# Introduction

Bayesians view inference as belief dynamics. It uses evidence to update prior belief to posterior beliefs which serve as prior beliefs for future evidence.

Decision theory is a formal theory of decision making under uncertainty. A decision problem consists of three parts:

1. Possible actions $a$
2. States of the world $s$
3. Possible consequences $c$

The question is "what is the best action or decision?"

If I want to answer the question, I need to measure the "goodness" of consequences with the $utility$ function $u$, and likelihood of states with probability distribution $p$. Then, I can choose the best action **with respect to model** maxmizes the expected utilities. How a model is for people depends on fidelity of model to their beliefs and perferences.

---

# Decision Model

Let me give you an example: should a patient be treated for disease?

1. Possible action: $a_T$(treat) or $a_N$(don't treat)
2. States of the world: $s_D$(Disease now) or $s_W$(Well now)
3. Possible consequences: $c_{WN}$(well shortly, no side effects), $c_{WS}$(well shortly, side effects), $c_{DN}$(disease for a long time, no side effects)

Likelihood of states:

$p(s_D)=0.3$

Utilities of possible consequences:

$$u_{WN}=100\\
u_{WS}=90\\
u_{DN}=0$$

Expected utilites of possible actions:

$$E(u_T) = p(s_D) \cdot u_{WS} + [1-p(s_D)] \cdot u_{WS} = 0.3 \times 90 + 0.7 \times 90 = 90 \\
E(u_N) = p(s_D) \cdot u_{DN} + [1-p(s_D)] \cdot u_{WN} = 0.3 \times 0 + 0.7 \times 100 = 70$$

Best decison:

$a_T$ because $90$ is greater than $70$.

---

# Bayesian Rule
 
In the previous example, the probability of disease, $p(s_D)$, is usually uncertain. In most case, I will use Bayesian inference to refine our estimate of the probability.

Bayes Rule (odds likelihood form):

$$\frac{P(H_i|E)}{P(H_j|E)}=\frac{P(E|H_i) \cdot P(H_i)}{P(E|H_j) \cdot P(H_j)}\\
P(H_i|E)=\frac{P(H_i) \cap P(E)}{P(E)}=\frac{P(E|H_i) \cdot P(H_i)}{\sum_jP(E|H_j) \cdot P(H_j)}$$
Terminology:

$P(H)$: The prior probability of $H$.

$P(E)$: The predictive probability of $E$.

$\frac{P(E|H_i)}{P(E|H_j)}$: The likelihood ratio for $H_i$ versue $H_j$.

$P(E|H)$: The likelihood for $E$ given $H$.

$P(H|E)$: The posterior probability of $H$ given $E$.

$\frac{P(H_i)}{P(H_j)}$: The prior odds ratio for $H_i$ versue $H_j$.

---

## Refine estimate

Now I need to continue the previous example. In order to make better decision, I need to know more about the probability of states of the world. Therefore, I am going to perform a test.

Test has two outcomes: $t_p(positive)$ and $t_N(negative)$. 

Quality of test is characterized by two numbers:

1. **Sensitivity**: Probability that test is positive if patient has disease --- $P(t_P|s_D)$

2. **Specificity**: Probability that test is negative if patient does not have disease --- $P(t_N|s_W)$

In the example, let's assume that $P(t_P|s_D)=0.95$ and $P(t_N|s_W)=0.85$.

How can I use the information to refine my estimate about probability?

1. If the test is *positive*, 
$$P(s_D|t_P)=\frac{P(t_P|s_D) \cdot P(s_D)}{P(t_P|s_D) \cdot P(s_D) + P(t_P|s_W) \cdot P(s_W)}\\
=\frac{0.95 \times 0.3}{0.95 \times 0.3 + 0.15 \times 0.7}\\
=0.731$$

Obviously, the best action is to treat.

2. If the test is *negative*,
$$P(s_D|t_N)=\frac{P(t_N|s_D) \cdot P(s_D)}{P(t_N|s_D) \cdot P(s_D) + P(t_N|s_W) \cdot P(s_W)}\\
=\frac{0.05 \times 0.3}{0.05 \times 0.3 + 0.85 \times 0.7}\\
=0.025$$
Obviously, the best action is not to treat.

Optimal policy is to treat if positive; don’t treat if negative. The decision or action is called Followtest($a_F$).

The whole process combines the decision theory and Bayesian inference.

---

# Gather information?

Usually, performing a test requires a cost, so how can I determine whether it is worthy performing a test (or you can say gather additional information)?

In this scenario, comapring the expected utilities is a good solution.

If I don't perform the test, the expected utilities ($E(a_T)$) is $90$.
If I performe the test, the expected utilities, $E(a_F)=P(t_P) \cdot E(a_T|t_P)+P(t_N) \cdot E(a_N|t_N)$, is $94.575$.

The expected utilities of $a_F$ is larger than $a_T$, so it is a good idea to perform a test.

The *Expected Value of Sample Information (EVSI)* is $94.575 - 90 = 4.575$, and *Expected Value of Perfect Information (EVPI)* is $(0.3 \times 90 + 0.7 \times 100 =)97 - 90 =7$.

As long as **EVSI** is greater than the cost of information, I will collect the information.

To analyze decision of whether to collect information:

• Find maximum expected utility option if we don't collect information

• Compute its expected utility $U_o$

• Find EVPI

• Compare EVPI with cost of information

• If EVPI is too small in relation to cost then stop; otherwise, compute EVSI

• Compare EVSI with cost of information

• Collect information if expected utility gain is greater than cost of information

---

# What if a Probability if unknown?

To model for the medical exampel, I rely on three probabilities:

1. Prior probability of disease

2. Sensitivity of test

3. Specificity of test

How does a Bayesian combine data and expert judgment?

• Use clinical judgment to quantify uncertainty about as a probability distribution

• Gather data

• Use Bayes rule to obtain posterior distribution for the unknown probability

• If appropriate, use clinical judgment to adjust results of studies to apply to a particular patient

---

Assign prior distribution to possible values of disease probability $p$. Although $p$ can be any real number between zero and 1, we pretend there are only 20 equally spaced possible values. Our prior distribution is consistent with our estimate $p=0.3$. Observe 10 **independent and identically distributed (iid)** cases. $(X_1, X_2, X_3, X_4, X_5, X_6, X_7, X_8, X_9, X_10) = (0, 1, 0, 0, 0, 0, 1, 0, 0, 1)$, Cases 2, 7, and 10 have disease; the rest do not.

How do we find the posterior distribution of the unknown probability?

```{r}
# Unit 1 Bayesian Updating Example: Inference about an unknown probability
# Calculate and plot prior and posterior distribution 
# for disease probability:  Discretized prior; 
# sample of 10 cases, 3 having disease

# Assume the unknow probability p can take on one of 20 evenly spaced values 
# between 0.025 and 0.975
pVals <- seq(length=20,from=0.025,to=0.975)

# Prior distribution: choose a prior distribution centered around 0.3 
priorDist <- c(0.033, 0.071, 0.099, 0.116, 0.117, 0.113, 0.103, 
               0.090, 0.074, 0.061, 0.045, 0.024, 0.016,
               0.013, 0.009, 0.006, 0.004, 0.003, 0.002, 0.001)

# Verify that the expected value of p is 0.3
sum(priorDist*pVals)

# Plot the prior distribution as a bar chart 
barplot(priorDist,main="Prior distribution for p",
        xlab="p", ylab="Prior Probability",names.arg=pVals,
        border="darkblue", col="lightblue",ylim=c(0,0.15))

# Calculate the posterior distribution of p after observing sample of 
# 10 cases, 3 having disease
numobs=10    # Number of observations
numd=3       # Number having the disease
lik = pVals^numd*(1-pVals)^(numobs-numd)  # Likelihood of data given p
pl <- priorDist * lik                     # prior times likelihood
postDist <- pl/sum(pl)                    # result of Bayes rule

# Plot the posterior distribution 
barplot(postDist,main="Posterior distribution for p",
xlab="p", ylab="Posterior Probability",names.arg=pVals,
border="darkblue", col="lightblue")

# Expected value of p given the observations
sum(pVals*postDist)

# Poterior cumulative distribution function
cdf = cumsum(postDist)      # calculate cumulative sum
round(rbind(pVals, cdf),4)  # print probability points and cdf at each point

# Prior and posterior probability that disease probabilty is between 0.2 and 0.4
indx = which(pVals>=0.2 & pVals<=0.4)  # Indices for probs between 0.2 and 0.4
sum(priorDist[indx])     # Prior prob that disease probability is between 0.2 and 0.4
sum(postDist[indx])      # Posterior prob that disease probability is between 0.2 and 0.4
```





















































