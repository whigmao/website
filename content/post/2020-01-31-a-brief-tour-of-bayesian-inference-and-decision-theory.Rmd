---
title: A Brief Tour of Bayesian Inference and Decision Theory
author: Guanghua Mao
date: '2020-01-31'
slug: a-brief-tour-of-bayesian-inference-and-decision-theory
categories:
  - Decision Theory
tags:
  - Bayesian
  - R
  - Math
---

# Introduction

Bayesians view inference as belief dynamics. It uses evidence to update prior belief to posterior beliefs which serve as prior beliefs for future evidence.

Decision theory is a formal theory of decision making under uncertainty. A decision problem consists of three parts:

1. Possible actions $a$
2. States of the world $s$
3. Possible consequences $c$

The question is "what is the best action or decision?"

If I want to answer the question, I need to measure the "goodness" of consequences with the $utility$ function $u$, and likelihood of states with probability distribution $p$. Then, I can choose the best action **with respect to model** maxmizes the expected utilities. How a model is for people depends on fidelity of model to their beliefs and perferences.

---

# Decision Model

Let me give you an example: should a patient be treated for disease?

1. Possible action: $a_T$(treat) or $a_N$(don't treat)
2. States of the world: $s_D$(Disease now) or $s_W$(Well now)
3. Possible consequences: $c_{WN}$(well shortly, no side effects), $c_{WS}$(well shortly, side effects), $c_{DN}$(disease for a long time, no side effects)

Likelihood of states:

$p(s_D)=0.3$

Utilities of possible consequences:

$$u_{WN}=100\\
u_{WS}=90\\
u_{DN}=0$$

Expected utilites of possible actions:

$$E(u_T) = p(s_D) \cdot u_{WS} + [1-p(s_D)] \cdot u_{WS} = 0.3 \times 90 + 0.7 \times 90 = 90 \\
E(u_N) = p(s_D) \cdot u_{DN} + [1-p(s_D)] \cdot u_{WN} = 0.3 \times 0 + 0.7 \times 100 = 70$$

Best decison:

$a_T$ because $90$ is greater than $70$.

---

# Bayesian Rule
 
In the previous example, the probability of disease, $p(s_D)$, is usually uncertain. In most case, I will use Bayesian inference to refine our estimate of the probability.

Bayes Rule (odds likelihood form):

$$\frac{P(H_i|E)}{P(H_j|E)}=\frac{P(E|H_i) \cdot P(H_i)}{P(E|H_j) \cdot P(H_j)}\\
P(H_i|E)=\frac{P(H_i) \cap P(E)}{P(E)}=\frac{P(E|H_i) \cdot P(H_i)}{\sum_jP(E|H_j) \cdot P(H_j)}$$
Terminology:

$P(H)$: The prior probability of $H$.

$P(E)$: The predictive probability of $E$.

$\frac{P(E|H_i)}{P(E|H_j)}$: The likelihood ratio for $H_i$ versue $H_j$.

$P(E|H)$: The likelihood for $E$ given $H$.

$P(H|E)$: The posterior probability of $H$ given $E$.

$\frac{P(H_i)}{P(H_j)}$: The prior odds ratio for $H_i$ versue $H_j$.

---

## Refine estimate

Now I need to continue the previous example. In order to make better decision, I need to know more about the probability of states of the world. Therefore, I am going to perform a test.

Test has two outcomes: $t_p(positive)$ and $t_N(negative)$. 

Quality of test is characterized by two numbers:

1. **Sensitivity**: Probability that test is positive if patient has disease --- $P(t_P|s_D)$

2. **Specificity**: Probability that test is negative if patient does not have disease --- $P(t_N|s_W)$

In the example, let's assume that $P(t_P|s_D)=0.95$ and $P(t_N|s_W)=0.85$.

How can I use the information to refine my estimate about probability?

1. If the test is *positive*, 
$$P(s_D|t_P)=\frac{P(t_P|s_D) \cdot P(s_D)}{P(t_P|s_D) \cdot P(s_D) + P(t_P|s_W) \cdot P(s_W)}\\
=\frac{0.95 \times 0.3}{0.95 \times 0.3 + 0.15 \times 0.7}\\
=0.731$$

Obviously, the best action is to treat.

2. If the test is *negative*,
$$P(s_D|t_N)=\frac{P(t_N|s_D) \cdot P(s_D)}{P(t_N|s_D) \cdot P(s_D) + P(t_N|s_W) \cdot P(s_W)}\\
=\frac{0.05 \times 0.3}{0.05 \times 0.3 + 0.85 \times 0.7}\\
=0.025$$
Obviously, the best action is not to treat.

Optimal policy is to treat if positive; don’t treat if negative. The decision or action is called Followtest($a_F$).

The whole process combines the decision theory and Bayesian inference.

---

# Gather information?

Usually, performing a test requires a cost, so how can I determine whether it is worthy performing a test (or you can say gather additional information)?

In this scenario, comapring the expected utilities is a good solution.

If I don't perform the test, the expected utilities ($E(a_T)$) is $90$.
If I performe the test, the expected utilities, $E(a_F)=P(t_P) \cdot E(a_T|t_P)+P(t_N) \cdot E(a_N|t_N)$, is $94.575$.

The expected utilities of $a_F$ is larger than $a_T$, so it is a good idea to perform a test.

The *Expected Value of Sample Information (EVSI)* is $94.575 - 90 = 4.575$, and *Expected Value of Perfect Information (EVPI)* is $(0.3 \times 90 + 0.7 \times 100 =)97 - 90 =7$.

As long as **EVSI** is greater than the cost of information, I will collect the information.

To analyze decision of whether to collect information:

• Find maximum expected utility option if we don't collect information

• Compute its expected utility $U_o$

• Find EVPI

• Compare EVPI with cost of information

• If EVPI is too small in relation to cost then stop; otherwise, compute EVSI

• Compare EVSI with cost of information

• Collect information if expected utility gain is greater than cost of information

---

# What if a Probability if unknown?

To model for the medical exampel, I rely on three probabilities:

1. Prior probability of disease

2. Sensitivity of test

3. Specificity of test

Usually these probabilities are estimated from data and/or expert judgment:

* "Randomized clinical trials have established that Test T has sensitivity 0.95 and specificity 0.85 for Disease D"

* "Given the presenting symptoms and my clinical judgment, I estimate a 30% probability that the patient has Disease D"


How does a Bayesian combine data and expert judgment?

• Use clinical judgment to quantify uncertainty about as a probability distribution

• Gather data

• Use Bayes rule to obtain posterior distribution for the unknown probability

• If appropriate, use clinical judgment to adjust results of studies to apply to a particular patient

---

# Example: Bayesian Inference about a Probability

Assign prior distribution to possible values of disease probability $p$. 

* Although $p$ can be any real number between zero and 1, we pretend there are only 20 equally spaced possible values. 

* Our prior distribution is consistent with our estimate $p=0.3$. 

Observe 10 **independent and identically distributed (iid)** cases. $(X_1, X_2, X_3, X_4, X_5, X_6, X_7, X_8, X_9, X_10) = (0, 1, 0, 0, 0, 0, 1, 0, 0, 1)$, Cases 2, 7, and 10 have disease; the rest do not.

How do we find the posterior distribution of the unknown probability?

## Posterior Distribution of Disease Parameter

In the above example, I will apply Bayes rule in this way:

1. I oberverd 3 cases of disease in 10 trials.

2. Likelihood of data is $p^3(1-p)^7$.

3. Multiply prior $g(p)$ times likelihood $p^3(1-p)^7$ and divide by sum:

$g(p|x_1,…,x_{10})=\frac{g(p)p^3(1-p)^7}{\sum_{p^,}g(p^,){p^,}^3(1-p^,)^7}$

Notice that the posterior distribution depends only on the number of cases with and without the disease.

```{r}
# Unit 1 Bayesian Updating Example: Inference about an unknown probability
# Calculate and plot prior and posterior distribution 
# for disease probability:  Discretized prior; 
# sample of 10 cases, 3 having disease

# Assume the unknow probability p can take on one of 20 evenly spaced values 
# between 0.025 and 0.975
pVals <- seq(length=20,from=0.025,to=0.975)

# Prior distribution: choose a prior distribution centered around 0.3 
priorDist <- c(0.033, 0.071, 0.099, 0.116, 0.117, 0.113, 0.103,
               0.090, 0.074, 0.061, 0.045, 0.024, 0.016,
               0.013, 0.009, 0.006, 0.004, 0.003, 0.002, 0.001)

# Verify that the expected value of p is 0.3
sum(priorDist*pVals)

# Plot the prior distribution as a bar chart 
barplot(priorDist,main="Prior distribution for p",
        xlab="p", ylab="Prior Probability",names.arg=pVals,
        border="darkblue", col="lightblue",ylim=c(0,0.15))

# Calculate the posterior distribution of p after observing sample of 
# 10 cases, 3 having disease
numobs=10    # Number of observations
numd=3       # Number having the disease
lik = pVals^numd*(1-pVals)^(numobs-numd)  # Likelihood of data given p
pl <- priorDist * lik                     # prior times likelihood
postDist <- pl/sum(pl)                    # result of Bayes rule

# Plot the posterior distribution 
barplot(postDist,main="Posterior distribution for p",
xlab="p", ylab="Posterior Probability",names.arg=pVals,
border="darkblue", col="lightblue")

# Expected value of p given the observations
sum(pVals*postDist)

# Poterior cumulative distribution function
cdf = cumsum(postDist)      # calculate cumulative sum
round(rbind(pVals, cdf),4)  # print probability points and cdf at each point

# Prior and posterior probability that disease probabilty is between 0.2 and 0.4
indx = which(pVals>=0.2 & pVals<=0.4)  # Indices for probs between 0.2 and 0.4
sum(priorDist[indx])     # Prior prob that disease probability is between 0.2 and 0.4
sum(postDist[indx])      # Posterior prob that disease probability is between 0.2 and 0.4
```

---

# Bayesian Learning and Sample Size

When the sample size is very large, the posterior distribution will be concentrated around the maximum likelihood estimate and is relatively insensitive to the prior distribution. We won't go too far wrong if we act as if the parameter is equal to the maximum likelihood estimate.

When the sample size is very small, the posterior distribution is highly dependent on the prior distribution. Reasonable people may disagree on the value of the parameter.

When the sample size is moderate, Bayesian learning can be a big improvement on either expert judgment alone or data alone. However, achieving the benefit requires careful modeling. In the next series of articles, I will share methods for constructing Bayesian models.

A powerful characteristic of the Bayesian approach is the flexibility to tailor results to moderatesized sub-populations. Bayesian estimate **shrinks** estimates of sub-population parameters toward population average. Amount of shrinkage depends on sample size and similarity of sub-population to overall population. Shrinkage improves estimates for small to moderate sized sub-populations.

---

# Some Concepts of Probability

* Classical - Probability is a ratio of favorable cases to total (equipossible) cases

* Frequency - Probability is the limiting value as the number of trials becomes infinite of the frequency of occurrence of a type of event

* Logical - Probability is a logical property of one’s state of information about a phenomenon

* Propensity - Probability is a propensity for certain kinds of physical event to occur

* Subjective - Probability is an ideal rational agent’s degree of belief about an uncertain event

* Algorithmic - The algorithmic probability of a finite sequence is the probability that a universal computer fed a random input will give the sequence as output

* Game Theoretic - Probability is an agent’s optimal “announced certainty” for an event in a multiagent game in which agents receive rewards that depend on both forecasts and outcomes

---

# Why be a Bayesian?

Arguments from theory:

* A coherent decision maker uses probability to represent uncertainty, uses utility to represent value, and maximizes expected utility.

* If you are not coherent then someone can make "Dutch book" on you (turn you into a "money pump")

Pragmatic arguments: 

* Useful and principled methodology for modeling inference, decision and learning

* Analyze engineering tradeoffs between accuracy, complexity and cost

* Represent and incorporate both empirical data and informed engineering judgment

* Handle small, moderate and large sample sizes and parameter sets

* Interpretability of results and understandability of model


Arguments from experience: 

* Successful applications attributed to decision theory




















































