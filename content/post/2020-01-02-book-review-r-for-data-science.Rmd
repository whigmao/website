---
title: R for Data Science
author: Guanghua Mao
date: '2020-01-02'
categories:
  - Original Articles
tags:
  - Book Review
  - Data Science
  - R
  - English
slug: book-review-r-for-data-science
---

After reading the book: *[R for Data Science](https://r4ds.had.co.nz/)*, I plan to write a book review to summary some important skills I learned from the book and shed new light on the future study direction. The book helps me understand the whole diagram about data science, and what role R plays in the diagram. However, the book is not a definitive guide. These are a lot of important topics, such as TensorFlow, model building and non-rectangular data, not appearing in the book. What motivates me to write the book review is that although the authors provide a clear workflow about data science, the book doesn't follow the workflow, also, there is too much redundant content which will burden readers. Thus, I am going to reorganize the structure and briefly and concisely summary the important information.

---

# 0. Saving Your Time

Workflow | Mission | Argument & Parameter
-------- | ------- | --------------------
Data Import | Read data | read_csv(file, skip=,comment=,na=,col_names=)
Data Import | Parsing files | parse_*(data,locale or col_types=cols(x=,y=))
Tidy data | gather columns into a new pair of variables | gather(the initial columns, name of column (key), name of column (value))
Tidy data | spread multiple rows into new pair of variables | spread(the initial column(key), value column(value))
Tidy data | pulls apart one column into multiple columns | separate(the initial column, new columns (into))
Tidy data | combines multiple columns into a single column | unite(new column's name, the initial columns, sep)
Data Transformation | Filter rows | filter(data, col_name == Values)
Data Transformation | Reorder the rows | arrange(data, desc(col_names))
Data Transformation | Select Columns | select(data, col_names)
Data Transformation | Add new variables | mutate(data, new variables = existing columns(+-*/))
Data Transformation | Grouped summaries | summarise(gropy_by(col_names),existing columns(STAT))
Data Transformation | Rename colnames | rename(data, new col_names = existing col_names)
Data Transformation | recode values | recode(data, new value = old value)
Data Visualization | visulaising your data | **read the last code chunk**


---

# 1. The Workflow

![Data Science Workflow](/post/2020-01-02-book-review-r-for-data-science_files/Data Science Workflow.png)

---

# 2. Data Import

In the section, I have learned how to read external data and parse a file.

## 1. Read External Data
In most case, we will import *CSV* file.

```{r}
library(tidyverse)
#the package I use is readr
height <- read_csv("the first line is metadata
                   the second line is metadata
                   #this is a comment
                   a,b,c
                   1,2,3
                   A,B,.",
                   skip=2,
                   comment="#",
                   na=".",
                   col_names = c("x","y","z"))
height
```
This is all you need to know to read $75$% of *CSV* files that you’ll encounter in practice. If you want to know more, please visit [readr](https://cran.r-project.org/web/packages/readr/readr.pdf).

Why I am not using `read.csv()` is the base R function will not produce tibble which is better than data frame and work less productive than `read_csv()`.

## 2. Parsing a file

`Parse_*()` functions take a character vertor and return a more specialised vector like a logical, integer, or date.

```{r}
str(parse_logical(c("TRUE","FALSE","NA")))
str(parse_integer(c("1", "2", "3")))
str(parse_date(c("2010-01-01", "1979-10-14")))
parse_datetime("20101010")
parse_date("1 janvier 2015", "%d %B %Y", locale = locale("fr"))
```

These functions are useful in their own right, but are also an important building block for readr. If parsing fails, you’ll get a warning:
```{r}
x <- parse_integer(c("123", "345", "abc", "123.45"))
problems(x)
```
Let me give you more example:
```{r}
parse_double("1,23")
```

There is a little problem. You can use the argument `locale = locale(decimal_mark="")` to solve the problem.
```{r}
parse_double("1,23",locale = locale(decimal_mark = ","))
```

Also, we may want to ingore the mark, whether it is ".", "," or "`".
```{r}
# Used in America
parse_number("$123,456,789")
#> [1] 1.23e+08

# Used in many parts of Europe
parse_number("123.456.789", locale = locale(grouping_mark = "."))
#> [1] 1.23e+08

# Used in Switzerland
parse_number("123'456'789", locale = locale(grouping_mark = "'"))
#> [1] 1.23e+08
```
When we plan to parse characters, we may need to specify the encoding.
```{r}
x1 <- "El Ni\xf1o was particularly bad this year"
x2 <- "\x82\xb1\x82\xf1\x82\xc9\x82\xbf\x82\xcd"
parse_character(x1, locale = locale(encoding = "Latin1"))
parse_character(x2, locale = locale(encoding = "Shift-JIS"))
```

In the first code chunk in the section, I give three examples on how to parse date and datetime, but in practice the situation is complicated. Therefore, I will write another article to fully explain how to prase date and datetime.

Now we need to know how to parse a file.

```{r}
challenge <- read_csv(readr_example("challenge.csv"))
```

You can know that the type of y column is not logic but date, so we need to parse the column.

```{r}
challenge <- read_csv(
  readr_example("challenge.csv"), 
  col_types = cols(
    x = col_double(),
    y = col_date()
  )
)
tail(challenge)
```
Now, it is correct.

---

# 3. Tidy Data
This chapter will give you a practical introduction to tidy data and the accompanying tools in the *tidyr* package. 

There are three interrelated rules which make a dataset tidy:

1. Each variable must have its own column.

2. Each observation must have its own row.

3. Each value must have its own cell.

That interrelationship leads to an even simpler set of practical instructions:

1. Put each dataset in a tibble.

2. Put each variable in a column.

There are two groups of complement argument to perform tidying data.

name | usage | parameters
---- | ---- | ----
gather | gather columns into a new pair of variables | the initial columns, name of column (key), name of column (value)
spread | spread multiple rows into new pair of variables | the initial column(key), value column(value)
seprarate | pulls apart one column into multiple columns | the initial column, new columns (into)
unite | combines multiple columns into a single column | new column's name, the initial columns, sep

If you just look at the table, it will make you confused, so I will give you examples one by one.

```{r}
table4a
# we want to gather 1999, 2000, because they are not variables but values.
table4a %>% gather('1999','2000',key = "year",value = "cases")
```
We can use `gather()` to tidy `table4b` in a similar fashion. The only difference is the variable stored in the cell values:
```{r}
table4b %>%
  gather(`1999`, `2000`, key = "year", value = "population")
```
Spreading is the opposite of gathering.
```{r}
head(table2)
#type column contains two variables
table2 %>%
  spread(key="type",value="count")
```

`Separate()` pulls apart one column into multiple columns, by splitting wherever a separator character appears.

```{r separate}
head(table3)
#We want to separate "rate" column into "cases" and "population"
table3 %>%
  separate(rate, into = c("cases","population"),sep = "/",convert = TRUE)
```

`unite()` is the inverse of `separate()`: it combines multiple columns into a single column.

```{r unit}
head(table5)
#Obviously, we can combine century and year into a single column
table5 %>%
  unite(year,century,year, sep = "")
```

You can use `na.rm=TRUE` to remove *NA* values.

---

# 4. Data Transformation

Often we will need to create some new variables or summaries, or maybe you just want to rename the variables or reorder the observations in order to make the data a little easier to work with. I will use *dplyr* packages.

Argument | Usage | Parameters
-------- | ----- | ----------
filter() | Filter rows | filter(data, col_name == Values)
arrange() | Reorder the rows | arrange(data, desc(col_names))
select() | Select Columns | select(data, col_names)
mutate() | Add new variables | mutate(data, new variables = existing columns(+-*/))
summarise() | Grouped summaries | summarise(gropy_by(col_names),existing columns(STAT))
rename() | Rename colnames | rename(data, new col_names = existing col_names)
recode() | recode values | recode(data, new value = old value)



```{r Data Transformation}
library(nycflights13)
head(flights)
#filer rows
flights %>%
  filter(month == 1, day >= 3)
#reorder the rows
flights %>%
  arrange(desc(dep_delay))
#select columns
flights %>%
  select(year, month, arr_time)
#Add new variables
flights %>%
  mutate(flying_time = arr_time-dep_time)
#Grouped summaries
flights %>%
  group_by(year,month,day) %>%
  summarise(delay=mean(dep_delay,na.rm = TRUE))
#rename colnames
flights %>%
  rename(new=year)
#recode values
a <- c('a','b','c')
recode(a,'a'='apple')
```

---

# 5. Data Visualization

>“The simple graph has brought more information to the data analyst’s mind than any other device.” — John Tukey

This chapter will teach you how to visualise your data using *ggplot2*. This chapter will teach you how to visualise your data using *ggplot2*. I will briefly cover key features of ggplot2. Later, I will introduce ggplot2 in detail.

## 1. Aesthetic mappings

```{r aes}
ggplot(mpg, aes(x=displ, y=hwy)) +
  geom_point(aes(color=class))
#you can change "color" to "size", "alpha" or "shape"
ggplot(mpg, aes(x=displ, y=hwy)) +
  geom_point(color="blue")
#pay attention to their difference
```

## 2. Facets

```{r facets}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy,color=class)) + 
  facet_wrap(~ class, nrow = 2)


ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy,color=class)) + 
  facet_grid(drv ~ cyl)
```

## 3. Geometric objects

```{r geometric}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy,color=class)) +
    geom_smooth(mapping = aes(x = displ, y = hwy),se=FALSE)
```

## 4. Position adjustments

```{r position}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "dodge")
```

## 5. Coordinate system

```{r coordinate}
bar <- ggplot(data = diamonds) + 
  geom_bar(
    mapping = aes(x = cut, fill = cut), 
    show.legend = FALSE,
    width = 1
  ) + 
  theme(aspect.ratio = 1) +
  labs(x = NULL, y = NULL)

bar + coord_flip()
bar + coord_polar()
```

## 6. Conclusion
```{r eval=FALSE}
ggplot(data = <DATA>) + 
  <GEOM_FUNCTION>(
     mapping = aes(<MAPPINGS>),
     stat = <STAT>, 
     position = <POSITION>
  ) +
  <COORDINATE_FUNCTION> +
  <FACET_FUNCTION>
```

# 6. Model
The book doesn't include too much content about modelling, so I will find more resources to extend the part.















































